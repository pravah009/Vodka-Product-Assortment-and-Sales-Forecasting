{"cells":[{"cell_type":"markdown","metadata":{"id":"3sVS0MGcQbhf"},"source":["# Libraries"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733112192497,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"cSy6oo9PQVd1"},"outputs":[],"source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5995,"status":"ok","timestamp":1733112192496,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"QEquxoDcQT2N","outputId":"a4301460-869c-4f8c-a4ab-4e496a84e4dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n"]}],"source":["!pip install catboost\n","!pip install xgboost\n","!pip install lightgbm\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733112192497,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"5N3mESS-QXyy"},"outputs":[],"source":["# Machine Learning Models\n","from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n","from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n","from xgboost import XGBRegressor\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from sklearn.ensemble import VotingRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import AdaBoostRegressor"]},{"cell_type":"markdown","metadata":{"id":"72YBlKr-nxol"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"collapsed":true,"executionInfo":{"elapsed":658,"status":"ok","timestamp":1733112193152,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"CHfXxeKZLhH_","outputId":"da3c69f5-fced-49f7-a799-a42c14669d25"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Store_Number  Perc_Eastern_Europeans  Gender Ratio  Temperature  Item_Code  \\\n","0          2802                    0.17         98.24         57.5     503010   \n","1          2705                    0.17         97.16         55.2     503010   \n","2          2801                    0.17         98.24         57.5     503010   \n","3           802                    0.19         94.33         65.4     503175   \n","4          2201                    0.76         94.38         49.1     503175   \n","\n","      Item_Name  Retail_Price  Count_Week_Instock  Normalized_Sales_$L52W  \\\n","0  Barton Vodka          6.99                  52                  4661.0   \n","1  Barton Vodka          6.49                  52                   100.0   \n","2  Barton Vodka          7.49                  39                     NaN   \n","3  Barton Vodka         12.99                  52                  4689.0   \n","4  Barton Vodka         13.99                  52                  3926.0   \n","\n","                    Sales Bucket  ... Package_Type_1L Package_Type_200-3gft  \\\n","0                 Sales included  ...               1                     0   \n","1                 Sales included  ...               1                     0   \n","2  Sales excluded for model test  ...               1                     0   \n","3                 Sales included  ...               0                     0   \n","4                 Sales included  ...               0                     0   \n","\n","  Package_Type_200ml Package_Type_375ml  Package_Type_700ml  \\\n","0                  0                  0                   0   \n","1                  0                  0                   0   \n","2                  0                  0                   0   \n","3                  0                  0                   0   \n","4                  0                  0                   0   \n","\n","   Package_Type_720ml  Package_Type_750gft  Package_Type_750ml  \\\n","0                   0                    0                   0   \n","1                   0                    0                   0   \n","2                   0                    0                   0   \n","3                   0                    0                   0   \n","4                   0                    0                   0   \n","\n","   Count_Week_Instock_Normalized  Cluster_Label  \n","0                           1.00              3  \n","1                           1.00              3  \n","2                           0.75              3  \n","3                           1.00              3  \n","4                           1.00              3  \n","\n","[5 rows x 100 columns]"],"text/html":["\n","  <div id=\"df-80631511-9e63-4611-9c99-7b0b77f3b538\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Store_Number</th>\n","      <th>Perc_Eastern_Europeans</th>\n","      <th>Gender Ratio</th>\n","      <th>Temperature</th>\n","      <th>Item_Code</th>\n","      <th>Item_Name</th>\n","      <th>Retail_Price</th>\n","      <th>Count_Week_Instock</th>\n","      <th>Normalized_Sales_$L52W</th>\n","      <th>Sales Bucket</th>\n","      <th>...</th>\n","      <th>Package_Type_1L</th>\n","      <th>Package_Type_200-3gft</th>\n","      <th>Package_Type_200ml</th>\n","      <th>Package_Type_375ml</th>\n","      <th>Package_Type_700ml</th>\n","      <th>Package_Type_720ml</th>\n","      <th>Package_Type_750gft</th>\n","      <th>Package_Type_750ml</th>\n","      <th>Count_Week_Instock_Normalized</th>\n","      <th>Cluster_Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2802</td>\n","      <td>0.17</td>\n","      <td>98.24</td>\n","      <td>57.5</td>\n","      <td>503010</td>\n","      <td>Barton Vodka</td>\n","      <td>6.99</td>\n","      <td>52</td>\n","      <td>4661.0</td>\n","      <td>Sales included</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2705</td>\n","      <td>0.17</td>\n","      <td>97.16</td>\n","      <td>55.2</td>\n","      <td>503010</td>\n","      <td>Barton Vodka</td>\n","      <td>6.49</td>\n","      <td>52</td>\n","      <td>100.0</td>\n","      <td>Sales included</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2801</td>\n","      <td>0.17</td>\n","      <td>98.24</td>\n","      <td>57.5</td>\n","      <td>503010</td>\n","      <td>Barton Vodka</td>\n","      <td>7.49</td>\n","      <td>39</td>\n","      <td>NaN</td>\n","      <td>Sales excluded for model test</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.75</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>802</td>\n","      <td>0.19</td>\n","      <td>94.33</td>\n","      <td>65.4</td>\n","      <td>503175</td>\n","      <td>Barton Vodka</td>\n","      <td>12.99</td>\n","      <td>52</td>\n","      <td>4689.0</td>\n","      <td>Sales included</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2201</td>\n","      <td>0.76</td>\n","      <td>94.38</td>\n","      <td>49.1</td>\n","      <td>503175</td>\n","      <td>Barton Vodka</td>\n","      <td>13.99</td>\n","      <td>52</td>\n","      <td>3926.0</td>\n","      <td>Sales included</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 100 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80631511-9e63-4611-9c99-7b0b77f3b538')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-80631511-9e63-4611-9c99-7b0b77f3b538 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-80631511-9e63-4611-9c99-7b0b77f3b538');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-51e890ae-e490-4e64-b1f9-1ff214684b51\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51e890ae-e490-4e64-b1f9-1ff214684b51')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-51e890ae-e490-4e64-b1f9-1ff214684b51 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":91}],"source":["import numpy as np\n","import pandas as pd\n","\n","# Loading the CSV files instead of Excel files\n","df = pd.read_csv('clustered_data_new.csv')\n","\n","# Display the first few rows to check the structure before merging\n","df.head()"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733112193152,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"3qFrU3VluNlq","outputId":"03b65b91-cde1-40f8-bb0d-e2d8299f19ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 60973 entries, 0 to 60972\n","Data columns (total 100 columns):\n"," #   Column                              Non-Null Count  Dtype  \n","---  ------                              --------------  -----  \n"," 0   Store_Number                        60973 non-null  int64  \n"," 1   Perc_Eastern_Europeans              60973 non-null  float64\n"," 2   Gender Ratio                        60973 non-null  float64\n"," 3   Temperature                         60973 non-null  float64\n"," 4   Item_Code                           60973 non-null  int64  \n"," 5   Item_Name                           60973 non-null  object \n"," 6   Retail_Price                        60973 non-null  float64\n"," 7   Count_Week_Instock                  60973 non-null  int64  \n"," 8   Normalized_Sales_$L52W              54894 non-null  float64\n"," 9   Sales Bucket                        60973 non-null  object \n"," 10  Store_Name                          60973 non-null  object \n"," 11  Open_Date                           60973 non-null  object \n"," 12  Market_Name                         60973 non-null  object \n"," 13  Store_Address                       60973 non-null  object \n"," 14  Households                          60973 non-null  int64  \n"," 15  Perc_HH_Income_above100K            60973 non-null  float64\n"," 16  Median_HH_Income                    60973 non-null  int64  \n"," 17  Average_Net_Worth                   60973 non-null  int64  \n"," 18  Perc_Population_Bachelor_Degree     60973 non-null  float64\n"," 19  Perc_Hispanic                       60973 non-null  float64\n"," 20  Perc_Asian                          60973 non-null  float64\n"," 21  Perc_African_American               60973 non-null  float64\n"," 22  Perc_Population_Age_50-70           60973 non-null  float64\n"," 23  US Whiskey                          60973 non-null  int64  \n"," 24  Tequila Under $65                   60973 non-null  int64  \n"," 25  Tequila Over $65                    60973 non-null  int64  \n"," 26  Scotch Under $75                    60973 non-null  int64  \n"," 27  Scotch Over $75                     60973 non-null  int64  \n"," 28  Vodka                               60973 non-null  int64  \n"," 29  Cordials                            60973 non-null  int64  \n"," 30  Brandy Under $85                    60973 non-null  int64  \n"," 31  Brandy Over $85                     60973 non-null  int64  \n"," 32  Cabernet Under $20                  60973 non-null  int64  \n"," 33  Cabernet $20-50                     60973 non-null  int64  \n"," 34  Cabernet Over $50                   60973 non-null  int64  \n"," 35  Chardonnay Under $20                60973 non-null  int64  \n"," 36  Chardonnay Over $20                 60973 non-null  int64  \n"," 37  Wine - Sparkling                    60973 non-null  int64  \n"," 38  Pinot Noir Under $20                60973 non-null  int64  \n"," 39  Pinot Noir Over $20                 60973 non-null  int64  \n"," 40  Sauvignon Blanc                     60973 non-null  int64  \n"," 41  French Champagne                    60973 non-null  int64  \n"," 42  Market_Sales_L52wk                  51557 non-null  float64\n"," 43  Count_Item_Location                 51557 non-null  float64\n"," 44  Store_Age_Days                      60973 non-null  int64  \n"," 45  High_Education_High_Income          60973 non-null  float64\n"," 46  Diversity_Index                     60973 non-null  float64\n"," 47  Age_Income_Ratio                    60973 non-null  float64\n"," 48  Price_Per_Household                 60973 non-null  float64\n"," 49  Vodka_Sales_Factor                  60973 non-null  float64\n"," 50  Household_Income_to_NetWorth_Ratio  60973 non-null  float64\n"," 51  Household_Vodka_Factor              60973 non-null  int64  \n"," 52  Education_Diversity_Factor          60973 non-null  float64\n"," 53  Diversity_Vodka_Factor              60973 non-null  float64\n"," 54  Age_HighIncome_Factor               60973 non-null  float64\n"," 55  Store_Size_Extra Large              60973 non-null  int64  \n"," 56  Store_Size_Large                    60973 non-null  int64  \n"," 57  Store_Size_Medium                   60973 non-null  int64  \n"," 58  Store_Size_Small                    60973 non-null  int64  \n"," 59  Wealth_Diversity_Index              60973 non-null  float64\n"," 60  Store_State_AZ                      60973 non-null  int64  \n"," 61  Store_State_CA                      60973 non-null  int64  \n"," 62  Store_State_CO                      60973 non-null  int64  \n"," 63  Store_State_CT                      60973 non-null  int64  \n"," 64  Store_State_DE                      60973 non-null  int64  \n"," 65  Store_State_FL                      60973 non-null  int64  \n"," 66  Store_State_GA                      60973 non-null  int64  \n"," 67  Store_State_IL                      60973 non-null  int64  \n"," 68  Store_State_IN                      60973 non-null  int64  \n"," 69  Store_State_KS                      60973 non-null  int64  \n"," 70  Store_State_KY                      60973 non-null  int64  \n"," 71  Store_State_LA                      60973 non-null  int64  \n"," 72  Store_State_MA                      60973 non-null  int64  \n"," 73  Store_State_MD                      60973 non-null  int64  \n"," 74  Store_State_MI                      60973 non-null  int64  \n"," 75  Store_State_MN                      60973 non-null  int64  \n"," 76  Store_State_MO                      60973 non-null  int64  \n"," 77  Store_State_NJ                      60973 non-null  int64  \n"," 78  Store_State_NM                      60973 non-null  int64  \n"," 79  Store_State_NV                      60973 non-null  int64  \n"," 80  Store_State_NY                      60973 non-null  int64  \n"," 81  Store_State_SC                      60973 non-null  int64  \n"," 82  Store_State_TN                      60973 non-null  int64  \n"," 83  Store_State_TX                      60973 non-null  int64  \n"," 84  Store_State_WA                      60973 non-null  int64  \n"," 85  Store_State_WI                      60973 non-null  int64  \n"," 86  Package_Type_1.5L                   60973 non-null  int64  \n"," 87  Package_Type_1.75L                  60973 non-null  int64  \n"," 88  Package_Type_1.75Lgft               60973 non-null  int64  \n"," 89  Package_Type_100ml                  60973 non-null  int64  \n"," 90  Package_Type_1L                     60973 non-null  int64  \n"," 91  Package_Type_200-3gft               60973 non-null  int64  \n"," 92  Package_Type_200ml                  60973 non-null  int64  \n"," 93  Package_Type_375ml                  60973 non-null  int64  \n"," 94  Package_Type_700ml                  60973 non-null  int64  \n"," 95  Package_Type_720ml                  60973 non-null  int64  \n"," 96  Package_Type_750gft                 60973 non-null  int64  \n"," 97  Package_Type_750ml                  60973 non-null  int64  \n"," 98  Count_Week_Instock_Normalized       60973 non-null  float64\n"," 99  Cluster_Label                       60973 non-null  int64  \n","dtypes: float64(24), int64(70), object(6)\n","memory usage: 46.5+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733112193152,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"wbKBpkgxHRuf","outputId":"a8e771fa-ce48-4fb7-ab0a-c08184f0cfe2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Store_Number', 'Perc_Eastern_Europeans', 'Gender Ratio', 'Temperature',\n","       'Item_Code', 'Item_Name', 'Retail_Price', 'Count_Week_Instock',\n","       'Normalized_Sales_$L52W', 'Sales Bucket', 'Store_Name', 'Open_Date',\n","       'Market_Name', 'Store_Address', 'Households',\n","       'Perc_HH_Income_above100K', 'Median_HH_Income', 'Average_Net_Worth',\n","       'Perc_Population_Bachelor_Degree', 'Perc_Hispanic', 'Perc_Asian',\n","       'Perc_African_American', 'Perc_Population_Age_50-70', 'US Whiskey',\n","       'Tequila Under $65', 'Tequila Over $65', 'Scotch Under $75',\n","       'Scotch Over $75', 'Vodka', 'Cordials', 'Brandy Under $85',\n","       'Brandy Over $85', 'Cabernet Under $20', 'Cabernet $20-50',\n","       'Cabernet Over $50', 'Chardonnay Under $20', 'Chardonnay Over $20',\n","       'Wine - Sparkling', 'Pinot Noir Under $20', 'Pinot Noir Over $20',\n","       'Sauvignon Blanc', 'French Champagne', 'Market_Sales_L52wk',\n","       'Count_Item_Location', 'Store_Age_Days', 'High_Education_High_Income',\n","       'Diversity_Index', 'Age_Income_Ratio', 'Price_Per_Household',\n","       'Vodka_Sales_Factor', 'Household_Income_to_NetWorth_Ratio',\n","       'Household_Vodka_Factor', 'Education_Diversity_Factor',\n","       'Diversity_Vodka_Factor', 'Age_HighIncome_Factor',\n","       'Store_Size_Extra Large', 'Store_Size_Large', 'Store_Size_Medium',\n","       'Store_Size_Small', 'Wealth_Diversity_Index', 'Store_State_AZ',\n","       'Store_State_CA', 'Store_State_CO', 'Store_State_CT', 'Store_State_DE',\n","       'Store_State_FL', 'Store_State_GA', 'Store_State_IL', 'Store_State_IN',\n","       'Store_State_KS', 'Store_State_KY', 'Store_State_LA', 'Store_State_MA',\n","       'Store_State_MD', 'Store_State_MI', 'Store_State_MN', 'Store_State_MO',\n","       'Store_State_NJ', 'Store_State_NM', 'Store_State_NV', 'Store_State_NY',\n","       'Store_State_SC', 'Store_State_TN', 'Store_State_TX', 'Store_State_WA',\n","       'Store_State_WI', 'Package_Type_1.5L', 'Package_Type_1.75L',\n","       'Package_Type_1.75Lgft', 'Package_Type_100ml', 'Package_Type_1L',\n","       'Package_Type_200-3gft', 'Package_Type_200ml', 'Package_Type_375ml',\n","       'Package_Type_700ml', 'Package_Type_720ml', 'Package_Type_750gft',\n","       'Package_Type_750ml', 'Count_Week_Instock_Normalized', 'Cluster_Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":93}],"source":["df.columns"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733112193153,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"tKpjYDjIH84z","outputId":"ad01df13-356a-4636-cc13-7fcc65b94845"},"outputs":[{"output_type":"stream","name":"stdout","text":["Store_Number                     0\n","Perc_Eastern_Europeans           0\n","Gender Ratio                     0\n","Temperature                      0\n","Item_Code                        0\n","                                ..\n","Package_Type_720ml               0\n","Package_Type_750gft              0\n","Package_Type_750ml               0\n","Count_Week_Instock_Normalized    0\n","Cluster_Label                    0\n","Length: 100, dtype: int64\n"]}],"source":["print(df.isna().sum())"]},{"cell_type":"markdown","metadata":{"id":"f9xzjrzporAE"},"source":["# Data Prep"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733112193153,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"ee91a94873fe2a06"},"outputs":[],"source":["sales_included = df[df['Sales Bucket'] == 'Sales included']\n","sales_excluded = df[df['Sales Bucket'] == 'Sales excluded for model test']"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733112193153,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"93d12d8ab5ef92b5","outputId":"2ba7018e-7f98-4973-b7ce-5e33a169cae2"},"outputs":[{"output_type":"stream","name":"stdout","text":["54894\n","6079\n","Sales Bucket\n","Sales included                   54894\n","Sales excluded for model test     6079\n","Name: count, dtype: int64\n"]}],"source":["print(sales_included.shape[0])\n","print(sales_excluded.shape[0])\n","print(df['Sales Bucket'].value_counts())"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1733112193600,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"8YBb6nvs4gnH"},"outputs":[],"source":["# Filling NAs\n","def fill_NAs(df):\n","  df_cleaned = df.copy()\n","\n","  # Group by 'Item Code' and 'Price Zone' and calculate the average 'L52W in Stock'\n","  average_l52w = df_cleaned.groupby(['Item_Code', 'Market_Name'])['Count_Week_Instock'].transform('mean')\n","  # Replace NaN values in 'L52W in Stock' with the calculated average\n","  df_cleaned['Count_Week_Instock'] = df_cleaned['Count_Week_Instock'].fillna(average_l52w)\n","\n","  df_cleaned['Market_Sales_L52wk'] = df_cleaned.groupby(['Item_Code'])['Market_Sales_L52wk'].transform(\n","    lambda x: x.fillna(x.mean()))\n","\n","  df_cleaned['Market_Sales_L52wk'] = df_cleaned['Market_Sales_L52wk'].fillna(\n","    df_cleaned.groupby(['Item_Code'])['Normalized_Sales_$L52W'].transform('mean'))\n","\n","  df_cleaned['Market_Sales_L52wk'] = df_cleaned['Market_Sales_L52wk'].fillna(\n","    df_cleaned.groupby(['Item_Code'])['Normalized_Sales_$L52W'].transform('mean'))\n","\n","  return df_cleaned\n","\n","\n","# Assuming your DataFrame is named 'df'\n","# Replace 'df' with the actual name of your DataFrame.\n","\n","df_cleaned = fill_NAs(df)"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733112193600,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"5NgSa_Vr8YKW"},"outputs":[],"source":["columns_to_log = [ 'Retail_Price', 'Households', 'Average_Net_Worth', 'Store_Age_Days',\n","                  'Vodka_Sales_Factor', 'Household_Income_to_NetWorth_Ratio',\n","                   'Wealth_Diversity_Index', 'Normalized_Sales_$L52W', 'Market_Sales_L52wk']\n","\n","for column in columns_to_log:\n","  # Add a small constant to avoid taking the log of zero\n","  df_cleaned['log_' + column] = np.log(df_cleaned[column] + 1e-6)"]},{"cell_type":"markdown","metadata":{"id":"KHMC7wefJ6XY"},"source":[]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733112193600,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"kbPI_RDv_P3c","outputId":"21a7e24c-5391-49ce-95f8-50b01bc3d292"},"outputs":[{"output_type":"stream","name":"stdout","text":["Net_Worth_Category\n","Low          15445\n","Medium       15302\n","Very High    15229\n","High         14997\n","Name: count, dtype: int64\n"]}],"source":["# Define the bins for Average Net Worth\n","bins = [df_cleaned[\"Average_Net_Worth\"].min(), df_cleaned[\"Average_Net_Worth\"].quantile(0.25), df_cleaned[\"Average_Net_Worth\"].quantile(0.5), df_cleaned[\"Average_Net_Worth\"].quantile(0.75), df_cleaned[\"Average_Net_Worth\"].max()]\n","labels = ['Low', 'Medium', 'High', 'Very High']\n","\n","# Assuming 'Average Net Worth' is a column in your DataFrame 'df_cleaned'\n","# You can replace 'Average Net Worth' with the actual column name in your DataFrame.\n","\n","df_cleaned['Net_Worth_Category'] = pd.cut(df_cleaned['Average_Net_Worth'], bins=bins, labels=labels, include_lowest=True)\n","\n","# Print the value counts of the new category column\n","print(df_cleaned['Net_Worth_Category'].value_counts())"]},{"cell_type":"code","execution_count":100,"metadata":{"executionInfo":{"elapsed":132,"status":"ok","timestamp":1733112193730,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"FQ06x6gqlpOU"},"outputs":[],"source":["# Create the 'Total Wine Partners' column and initialize it to 0\n","total_wine_partners = [\n","    \"Tower Vodka\", \"Summum Vodka\", \"Hope Vodka\", \"Purity Vodka Connoisseur 51\", \"Classic Club Vodka\",\n","    \"The American Plains Vodka\", \"Froggy B Vodka\", \"Roberto Cavalli Vodka\", \"Akva Organic Swedish Vodka\",\n","    \"Gallant Vodka\", \"Opulent Vodka\", \"Veil Vodka\", \"Starr Blu Vodka\", \"Lyna Vodka\", \"Karkov Vodka\",\n","    \"Prairie Organic Vodka\", \"Pau Maui Handcrafted Vodka\", \"Eight Degrees Vodka\", \"Esme Black Shield Vodka\",\n","    \"Greenhouse Organic Vodka\", \"ABK6 Organic Vodka\", \"Ivanhalder's 1815 Vodka\", \"Stateside Urbancraft Vodka\",\n","    \"3 Howls Blood Orange Vodka\"\n","]\n","\n","# Create the 'Spirits_Direct' column and initialize it to 0\n","df_cleaned['Spirits_Direct'] = 0\n","\n","# Check if the 'Item_Name' column contains any partnered brand name\n","df_cleaned['Spirits_Direct'] = df_cleaned['Item_Name'].apply(\n","    lambda x: 1 if any(partner in str(x) for partner in total_wine_partners) else 0\n",")"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":1294,"status":"ok","timestamp":1733112195131,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"yi8xdnd1wWxg"},"outputs":[],"source":["# Define a list of common flavor keywords associated with flavored vodkas\n","flavor_keywords = [\n","    'Apple', 'Apricot', 'Berry', 'Blackberry', 'Blueberry', 'Cherry', 'Citrus', 'Coconut', 'Cranberry',\n","    'Grape', 'Grapefruit', 'Lemon', 'Lime', 'Mango', 'Melon', 'Orange', 'Peach', 'Pear', 'Pineapple',\n","    'Raspberry', 'Strawberry', 'Vanilla', 'Watermelon', 'Pepper', 'Chocolate', 'Espresso', 'Coffee',\n","    'Caramel', 'Honey', 'Cinnamon', 'Peppermint', 'Whipped', 'Cake', 'Marshmallow', 'Butterscotch',\n","    'vanilla', 'citrus', 'berry', 'peach', 'apple', 'lemon', 'lime', 'orange', 'raspberry',\n","    'strawberry', 'cherry', 'pineapple', 'mango', 'coconut', 'pepper', 'chocolate', 'caramel',\n","    'coffee', 'espresso', 'honey', 'ginger', 'melon', 'grape', 'pomegranate', 'watermelon',\n","    'cucumber', 'peppermint', 'cinnamon', 'spice', 'tea', 'mint', 'cake', 'whipped', 'cream',\n","    'butterscotch', 'toffee', 'hazelnut', 'almond', 'fig', 'apricot', 'pear', 'passion fruit',\n","    'kiwi', 'blueberry', 'blackberry', 'cranberry', 'grapefruit', 'tangerine', 'blood orange',\n","    'hibiscus', 'lavender', 'rose', 'elderflower', 'lychee', 'papaya', 'guava', 'dragonfruit',\n","    'acai', 'jalapeno', 'chipotle', 'sriracha', 'wasabi', 'bacon', 'smoked', 'maple', 'pumpkin',\n","    'smores', 'birthday cake', 'cotton candy', 'bubblegum', 'root beer', 'cola', 'gingerbread',\n","    'candy cane', 'sugar cookie', 'salted caramel', 'pecan', 'walnut', 'macadamia', 'pistachio',\n","    'chai', 'matcha', 'mocha', 'hazelnut', 'almond', 'butter', 'biscuit', 'cookie', 'brownie',\n","    'fudge', 'truffle', 'nougat', 'praline', 'marzipan', 'amaretto', 'tiramisu', 'baklava',\n","    'bakery', 'dessert', 'pastry', 'confection', 'sweet', 'sour', 'spicy', 'herb', 'botanical',\n","    'infusion', 'essence', 'extract', 'liqueur', 'cordial', 'schnapps'\n","]\n","\n","# Create the 'Flavored_Vodka' column and initialize it to 0\n","df_cleaned['Flavored_Vodka'] = 0\n","\n","# Function to check if any flavor keyword is in the item name\n","def is_flavored_vodka(item_name):\n","    # Convert item name to string and check for each keyword\n","    return any(keyword.lower() in str(item_name).lower() for keyword in flavor_keywords)\n","\n","# Apply the function to the 'Item_Name' column\n","df_cleaned['Flavored_Vodka'] = df_cleaned['Item_Name'].apply(is_flavored_vodka).astype(int)"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1733112195279,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"aOfn1wiu_Q6_"},"outputs":[],"source":["# Brand recognition\n","brand_keywords = [\n","    'Smirnoff', 'Absolut', 'Zubrowka', 'Magic Moments', 'Arkhangelskaya', 'Zoladkowa', 'Grey Goose', 'Soplica', 'Pyat Ozer',\n","    'Nemiroff', 'Belenkaya', 'Skyy', 'Talka', 'Ketel One', 'Finlandia', 'Russian Standard', 'Wodka Gorbatschow', 'Tsarskaya',\n","    'Imperial Collection Gold', 'Green Mark', 'Belaya Bereza'\n","]\n","\n","# Create the 'Top20_Vodka' column and initialize it to 0\n","df_cleaned['Top20_Vodka'] = 0\n","\n","# Function to check if any brand keyword is in the item name\n","def is_top20_vodka(item_name):\n","    # Convert item name to string and check for each keyword\n","    return any(keyword.lower() in str(item_name).lower() for keyword in brand_keywords)\n","\n","# Apply the function to the 'Item_Name' column\n","df_cleaned['Top20_Vodka'] = df_cleaned['Item_Name'].apply(is_top20_vodka).astype(int)"]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733112195279,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"Uj8ApkhsA_W_"},"outputs":[],"source":["# List of columns to process\n","columns_to_engineer = [\n","    'US Whiskey', 'Tequila Under $65', 'Tequila Over $65',\n","    'Scotch Under $75', 'Scotch Over $75', 'Vodka', 'Cordials',\n","    'Brandy Under $85', 'Brandy Over $85', 'Cabernet Under $20', 'Cabernet $20-50', 'Cabernet Over $50', 'Chardonnay Under $20', 'Chardonnay Over $20', 'Wine - Sparkling', 'Pinot Noir Under $20', 'Pinot Noir Over $20', 'Sauvignon Blanc', 'French Champagne'\n","]\n","\n","for col in columns_to_engineer:\n","    df_cleaned[f'{col}_engineered'] = df_cleaned[col] + 1\n","\n","df_cleaned['Vodka_Tequila_Under_65_Ratio'] = df_cleaned['Vodka_engineered']/df_cleaned['Tequila Under $65_engineered']\n","df_cleaned['Vodka_Tequila_Over_65_Ratio'] = df_cleaned['Vodka_engineered']/df_cleaned['Tequila Over $65_engineered']\n","\n","# Calculate the average wine value\n","wine_columns = [\n","    'Cabernet Under $20_engineered', 'Cabernet $20-50_engineered', 'Cabernet Over $50_engineered',\n","    'Chardonnay Under $20_engineered', 'Chardonnay Over $20_engineered', 'Wine - Sparkling_engineered',\n","    'Pinot Noir Under $20_engineered', 'Pinot Noir Over $20_engineered', 'Sauvignon Blanc_engineered',\n","    'French Champagne_engineered'\n","]\n","\n","df_cleaned['Average_Wine_Value'] = df_cleaned[wine_columns].mean(axis=1)\n","\n","# Create ratio variable\n","df_cleaned['Vodka_Wine_Ratio'] = df_cleaned['Vodka_engineered']/df_cleaned['Average_Wine_Value']"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":151,"status":"ok","timestamp":1733112195429,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"t0r-Q_g4p6FJ","outputId":"188d8f03-b4f0-4ee5-d544-7efd04dd40f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 60973 entries, 0 to 60972\n","Columns: 136 entries, Store_Number to Vodka_Wine_Ratio\n","dtypes: category(1), float64(37), int64(92), object(6)\n","memory usage: 62.9+ MB\n"]}],"source":["df_cleaned.info()"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733112195429,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"GYwv03WtqVsn","outputId":"2488d921-265e-4523-ae62-bec4033a7bb4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Store_Number', 'Perc_Eastern_Europeans', 'Gender Ratio', 'Temperature',\n","       'Item_Code', 'Item_Name', 'Retail_Price', 'Count_Week_Instock',\n","       'Normalized_Sales_$L52W', 'Sales Bucket',\n","       ...\n","       'Chardonnay Over $20_engineered', 'Wine - Sparkling_engineered',\n","       'Pinot Noir Under $20_engineered', 'Pinot Noir Over $20_engineered',\n","       'Sauvignon Blanc_engineered', 'French Champagne_engineered',\n","       'Vodka_Tequila_Under_65_Ratio', 'Vodka_Tequila_Over_65_Ratio',\n","       'Average_Wine_Value', 'Vodka_Wine_Ratio'],\n","      dtype='object', length=136)"]},"metadata":{},"execution_count":105}],"source":["df_cleaned.columns"]},{"cell_type":"markdown","metadata":{"id":"qVGyu_2moE5W"},"source":["# XGBoost"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":1533,"status":"ok","timestamp":1733112249235,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"5QjkLmet2Hkx","outputId":"7ab7976d-0729-4380-a2fa-25a11c192e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num', StandardScaler(),\n","                                                  ['Vodka',\n","                                                   'Count_Week_Instock_Normalized',\n","                                                   'log_Retail_Price',\n","                                                   'log_Households',\n","                                                   'log_Store_Age_Days',\n","                                                   'Vodka_Tequila_Under_65_Ratio',\n","                                                   'Vodka_Tequila_Over_65_Ratio',\n","                                                   'Vodka_Wine_Ratio']),\n","                                                 ('cat',\n","                                                  OneHotEncoder(drop='first'),\n","                                                  ['Store_Size_Extra Large',\n","                                                   'Store_Size_Large',\n","                                                   'St...\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.05,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=6, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=500, n_jobs=None,\n","                              num_parallel_tree=None, random_state=2424, ...))])"],"text/html":["<style>#sk-container-id-7 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-7 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-7 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-7 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-7 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-7 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-7 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-7 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-7 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-7 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-7 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-7 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-7 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-7 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-7 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-7 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"â–¸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-7 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-7 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-7 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"â–¾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-7 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-7 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-7 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-7 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-7 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-7 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-7 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-7 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-7 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-7 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n","                                                  [&#x27;Vodka&#x27;,\n","                                                   &#x27;Count_Week_Instock_Normalized&#x27;,\n","                                                   &#x27;log_Retail_Price&#x27;,\n","                                                   &#x27;log_Households&#x27;,\n","                                                   &#x27;log_Store_Age_Days&#x27;,\n","                                                   &#x27;Vodka_Tequila_Under_65_Ratio&#x27;,\n","                                                   &#x27;Vodka_Tequila_Over_65_Ratio&#x27;,\n","                                                   &#x27;Vodka_Wine_Ratio&#x27;]),\n","                                                 (&#x27;cat&#x27;,\n","                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n","                                                  [&#x27;Store_Size_Extra Large&#x27;,\n","                                                   &#x27;Store_Size_Large&#x27;,\n","                                                   &#x27;St...\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.05,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=6, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=500, n_jobs=None,\n","                              num_parallel_tree=None, random_state=2424, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n","                                                  [&#x27;Vodka&#x27;,\n","                                                   &#x27;Count_Week_Instock_Normalized&#x27;,\n","                                                   &#x27;log_Retail_Price&#x27;,\n","                                                   &#x27;log_Households&#x27;,\n","                                                   &#x27;log_Store_Age_Days&#x27;,\n","                                                   &#x27;Vodka_Tequila_Under_65_Ratio&#x27;,\n","                                                   &#x27;Vodka_Tequila_Over_65_Ratio&#x27;,\n","                                                   &#x27;Vodka_Wine_Ratio&#x27;]),\n","                                                 (&#x27;cat&#x27;,\n","                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n","                                                  [&#x27;Store_Size_Extra Large&#x27;,\n","                                                   &#x27;Store_Size_Large&#x27;,\n","                                                   &#x27;St...\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.05,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=6, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=500, n_jobs=None,\n","                              num_parallel_tree=None, random_state=2424, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n","                                 [&#x27;Vodka&#x27;, &#x27;Count_Week_Instock_Normalized&#x27;,\n","                                  &#x27;log_Retail_Price&#x27;, &#x27;log_Households&#x27;,\n","                                  &#x27;log_Store_Age_Days&#x27;,\n","                                  &#x27;Vodka_Tequila_Under_65_Ratio&#x27;,\n","                                  &#x27;Vodka_Tequila_Over_65_Ratio&#x27;,\n","                                  &#x27;Vodka_Wine_Ratio&#x27;]),\n","                                (&#x27;cat&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n","                                 [&#x27;Store_Size_Extra Large&#x27;, &#x27;Store_Size_Large&#x27;,\n","                                  &#x27;Store_Size_Medium&#x27;, &#x27;Store_Size_Sma...\n","                                  &#x27;Store_State_DE&#x27;, &#x27;Store_State_FL&#x27;,\n","                                  &#x27;Store_State_GA&#x27;, &#x27;Store_State_IL&#x27;,\n","                                  &#x27;Store_State_IN&#x27;, &#x27;Store_State_KS&#x27;,\n","                                  &#x27;Store_State_KY&#x27;, &#x27;Store_State_LA&#x27;,\n","                                  &#x27;Store_State_MA&#x27;, &#x27;Store_State_MD&#x27;,\n","                                  &#x27;Store_State_MI&#x27;, &#x27;Store_State_MN&#x27;,\n","                                  &#x27;Store_State_MO&#x27;, &#x27;Store_State_NJ&#x27;,\n","                                  &#x27;Store_State_NM&#x27;, &#x27;Store_State_NV&#x27;,\n","                                  &#x27;Store_State_NY&#x27;, &#x27;Store_State_SC&#x27;,\n","                                  &#x27;Store_State_TN&#x27;, &#x27;Store_State_TX&#x27;,\n","                                  &#x27;Store_State_WA&#x27;, &#x27;Store_State_WI&#x27;, ...])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Vodka&#x27;, &#x27;Count_Week_Instock_Normalized&#x27;, &#x27;log_Retail_Price&#x27;, &#x27;log_Households&#x27;, &#x27;log_Store_Age_Days&#x27;, &#x27;Vodka_Tequila_Under_65_Ratio&#x27;, &#x27;Vodka_Tequila_Over_65_Ratio&#x27;, &#x27;Vodka_Wine_Ratio&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Store_Size_Extra Large&#x27;, &#x27;Store_Size_Large&#x27;, &#x27;Store_Size_Medium&#x27;, &#x27;Store_Size_Small&#x27;, &#x27;Store_State_AZ&#x27;, &#x27;Store_State_CA&#x27;, &#x27;Store_State_CO&#x27;, &#x27;Store_State_CT&#x27;, &#x27;Store_State_DE&#x27;, &#x27;Store_State_FL&#x27;, &#x27;Store_State_GA&#x27;, &#x27;Store_State_IL&#x27;, &#x27;Store_State_IN&#x27;, &#x27;Store_State_KS&#x27;, &#x27;Store_State_KY&#x27;, &#x27;Store_State_LA&#x27;, &#x27;Store_State_MA&#x27;, &#x27;Store_State_MD&#x27;, &#x27;Store_State_MI&#x27;, &#x27;Store_State_MN&#x27;, &#x27;Store_State_MO&#x27;, &#x27;Store_State_NJ&#x27;, &#x27;Store_State_NM&#x27;, &#x27;Store_State_NV&#x27;, &#x27;Store_State_NY&#x27;, &#x27;Store_State_SC&#x27;, &#x27;Store_State_TN&#x27;, &#x27;Store_State_TX&#x27;, &#x27;Store_State_WA&#x27;, &#x27;Store_State_WI&#x27;, &#x27;Package_Type_1.5L&#x27;, &#x27;Package_Type_1.75L&#x27;, &#x27;Package_Type_1.75Lgft&#x27;, &#x27;Package_Type_100ml&#x27;, &#x27;Package_Type_1L&#x27;, &#x27;Package_Type_200-3gft&#x27;, &#x27;Package_Type_200ml&#x27;, &#x27;Package_Type_375ml&#x27;, &#x27;Package_Type_700ml&#x27;, &#x27;Package_Type_720ml&#x27;, &#x27;Package_Type_750gft&#x27;, &#x27;Package_Type_750ml&#x27;, &#x27;Cluster_Label&#x27;, &#x27;Spirits_Direct&#x27;, &#x27;Flavored_Vodka&#x27;, &#x27;Top20_Vodka&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=6, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=500, n_jobs=None,\n","             num_parallel_tree=None, random_state=2424, ...)</pre></div> </div></div></div></div></div></div>"]},"metadata":{},"execution_count":109}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the features and target\n","\n","# Split the data into 'data' and 'pred' based on 'Sales Bucket'\n","data = df_cleaned[df_cleaned['Sales Bucket'] == 'Sales included']\n","pred = df_cleaned[df_cleaned['Sales Bucket'] == 'Sales excluded for model test']\n","\n","# Define the features and target for 'data'\n","X = data[['Vodka', 'Store_Size_Extra Large',\n","          'Store_Size_Large', 'Store_Size_Medium', 'Store_Size_Small', 'Store_State_AZ', 'Store_State_CA',\n","          'Store_State_CO', 'Store_State_CT', 'Store_State_DE', 'Store_State_FL', 'Store_State_GA',\n","          'Store_State_IL', 'Store_State_IN', 'Store_State_KS', 'Store_State_KY', 'Store_State_LA',\n","          'Store_State_MA', 'Store_State_MD', 'Store_State_MI', 'Store_State_MN', 'Store_State_MO',\n","          'Store_State_NJ', 'Store_State_NM', 'Store_State_NV', 'Store_State_NY', 'Store_State_SC',\n","          'Store_State_TN', 'Store_State_TX', 'Store_State_WA', 'Store_State_WI', 'Package_Type_1.5L',\n","          'Package_Type_1.75L', 'Package_Type_1.75Lgft', 'Package_Type_100ml', 'Package_Type_1L',\n","          'Package_Type_200-3gft', 'Package_Type_200ml', 'Package_Type_375ml', 'Package_Type_700ml',\n","          'Package_Type_720ml', 'Package_Type_750gft', 'Package_Type_750ml', 'Count_Week_Instock_Normalized',\n","          'log_Retail_Price', 'log_Households', 'log_Store_Age_Days', 'Cluster_Label',\n","          'Vodka_Tequila_Under_65_Ratio', 'Vodka_Tequila_Over_65_Ratio', 'Vodka_Wine_Ratio',\n","          'Spirits_Direct', 'Flavored_Vodka', 'Top20_Vodka']]\n","y = data['Normalized_Sales_$L52W']\n","\n","# Split 'data' into training + validation (90%) and holdout (10%)\n","X_train_val, X_holdout, y_train_val, y_holdout = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","# Split the training + validation set into training (80%) and validation (20%)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n","\n","# Preprocessing pipeline\n","numerical_features = ['Vodka', 'Count_Week_Instock_Normalized', 'log_Retail_Price',\n","                      'log_Households', 'log_Store_Age_Days', 'Vodka_Tequila_Under_65_Ratio',\n","                      'Vodka_Tequila_Over_65_Ratio', 'Vodka_Wine_Ratio']\n","categorical_features = ['Store_Size_Extra Large', 'Store_Size_Large', 'Store_Size_Medium',\n","                        'Store_Size_Small', 'Store_State_AZ', 'Store_State_CA', 'Store_State_CO',\n","                        'Store_State_CT', 'Store_State_DE', 'Store_State_FL', 'Store_State_GA',\n","                        'Store_State_IL', 'Store_State_IN', 'Store_State_KS', 'Store_State_KY',\n","                        'Store_State_LA', 'Store_State_MA', 'Store_State_MD', 'Store_State_MI',\n","                        'Store_State_MN', 'Store_State_MO', 'Store_State_NJ', 'Store_State_NM',\n","                        'Store_State_NV', 'Store_State_NY', 'Store_State_SC', 'Store_State_TN',\n","                        'Store_State_TX', 'Store_State_WA', 'Store_State_WI', 'Package_Type_1.5L',\n","                        'Package_Type_1.75L', 'Package_Type_1.75Lgft', 'Package_Type_100ml',\n","                        'Package_Type_1L', 'Package_Type_200-3gft', 'Package_Type_200ml',\n","                        'Package_Type_375ml', 'Package_Type_700ml', 'Package_Type_720ml',\n","                        'Package_Type_750gft', 'Package_Type_750ml', 'Cluster_Label',\n","                        'Spirits_Direct', 'Flavored_Vodka', 'Top20_Vodka']\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numerical_features),\n","        ('cat', OneHotEncoder(drop='first'), categorical_features)\n","    ]\n",")\n","\n","# Import the required XGBoost library\n","from xgboost import XGBRegressor\n","\n","# Initialize the XGBoost regressor\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","    objective='reg:squarederror',\n","    n_estimators=500,\n","    learning_rate=0.05,\n","    max_depth=6,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    random_state=2424\n","))])\n","\n","# Train the model\n","xgboost_pipeline.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":110,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1552,"status":"ok","timestamp":1733112250786,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"6fAXfxy53hVn","outputId":"6e8b574a-8ed3-41b8-cd67-f6b962a6aefd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["XGBoost Model Performance:\n","Training RMSE: 5722.4524, MAE: 2138.8038, RÂ²: 0.8814\n","Validation RMSE: 14647.0310, MAE: 2843.3127, RÂ²: 0.2848\n","Holdout RMSE: 10962.0688, MAE: 2692.0637, RÂ²: 0.6604\n"]}],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Predict on training, validation, and holdout sets\n","y_train_pred = xgboost_pipeline.predict(X_train)\n","y_val_pred = xgboost_pipeline.predict(X_val)\n","y_holdout_pred = xgboost_pipeline.predict(X_holdout)\n","\n","# Calculate RMSE and MAE for training, validation, and holdout sets\n","train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n","val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n","holdout_rmse = mean_squared_error(y_holdout, y_holdout_pred, squared=False)\n","\n","train_mae = mean_absolute_error(y_train, y_train_pred)\n","val_mae = mean_absolute_error(y_val, y_val_pred)\n","holdout_mae = mean_absolute_error(y_holdout, y_holdout_pred)\n","\n","# Calculate RÂ² for training, validation, and holdout sets\n","train_r2 = xgboost_pipeline.score(X_train, y_train)\n","val_r2 = xgboost_pipeline.score(X_val, y_val)\n","holdout_r2 = xgboost_pipeline.score(X_holdout, y_holdout)\n","\n","# Print metrics\n","print(\"XGBoost Model Performance:\")\n","print(f\"Training RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}, RÂ²: {train_r2:.4f}\")\n","print(f\"Validation RMSE: {val_rmse:.4f}, MAE: {val_mae:.4f}, RÂ²: {val_r2:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse:.4f}, MAE: {holdout_mae:.4f}, RÂ²: {holdout_r2:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"9yf3Dxcng5VM"},"source":["# Random Forest"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176689,"status":"ok","timestamp":1733112432243,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"qWqbhGDlg4jA","outputId":"499c3e54-6e96-4c50-eaf5-b8af4f6268a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Random Forest Model Performance:\n","Training RMSE: 6966.4584, MAE: 2156.2656, RÂ²: 0.8242\n","Validation RMSE: 15635.8856, MAE: 2644.5398, RÂ²: 0.1850\n","Holdout RMSE: 10916.0043, MAE: 2493.5809, RÂ²: 0.6633\n"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Initialize the Random Forest regressor\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        n_estimators=500,\n","        max_depth=10,  # Set max_depth to prevent overfitting; adjust as needed\n","        min_samples_split=5,  # Controls tree splitting; adjust for performance\n","        random_state=2424\n","    ))\n","])\n","\n","# Train the Random Forest model\n","random_forest_pipeline.fit(X_train, y_train)\n","\n","# Predict on training, validation, and holdout sets\n","y_train_pred_rf = random_forest_pipeline.predict(X_train)\n","y_val_pred_rf = random_forest_pipeline.predict(X_val)\n","y_holdout_pred_rf = random_forest_pipeline.predict(X_holdout)\n","\n","# Calculate RMSE and MAE for training, validation, and holdout sets\n","train_rmse_rf = mean_squared_error(y_train, y_train_pred_rf, squared=False)\n","val_rmse_rf = mean_squared_error(y_val, y_val_pred_rf, squared=False)\n","holdout_rmse_rf = mean_squared_error(y_holdout, y_holdout_pred_rf, squared=False)\n","\n","train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n","val_mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n","holdout_mae_rf = mean_absolute_error(y_holdout, y_holdout_pred_rf)\n","\n","# Calculate RÂ² for training, validation, and holdout sets\n","train_r2_rf = random_forest_pipeline.score(X_train, y_train)\n","val_r2_rf = random_forest_pipeline.score(X_val, y_val)\n","holdout_r2_rf = random_forest_pipeline.score(X_holdout, y_holdout)\n","\n","# Print metrics\n","print(\"Random Forest Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_rf:.4f}, MAE: {train_mae_rf:.4f}, RÂ²: {train_r2_rf:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_rf:.4f}, MAE: {val_mae_rf:.4f}, RÂ²: {val_r2_rf:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_rf:.4f}, MAE: {holdout_mae_rf:.4f}, RÂ²: {holdout_r2_rf:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"LAhrakhzAHEB"},"source":["#Ensemble-XGB+RF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196493,"status":"ok","timestamp":1732566875893,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"Vn5r6bFsAGlQ","outputId":"d04f8b59-f12b-405b-d8e7-f422d1fb93a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble Model Performance:\n","Training RMSE: 6054.1962, MAE: 2060.2014, RÂ²: 0.8672\n","Validation RMSE: 15094.6589, MAE: 2660.9694, RÂ²: 0.2405\n","Holdout RMSE: 10868.7632, MAE: 2488.8975, RÂ²: 0.6662\n"]}],"source":["import numpy as np\n","from sklearn.ensemble import VotingRegressor\n","\n","# Assuming xgboost_pipeline and random_forest_pipeline are already defined and trained\n","\n","# Create the ensemble model using VotingRegressor\n","ensemble_model = VotingRegressor(\n","    estimators=[('xgboost', xgboost_pipeline), ('random_forest', random_forest_pipeline)],\n","    weights=[1,1] #weights can be adjusted based on model performance\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Predict on training, validation, and holdout sets\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","# Evaluate the ensemble model\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","print(\"Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"sMMLjYIwQLXG"},"source":["# Ensemble 5"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216256,"status":"ok","timestamp":1733112657849,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"a73KE-M9GE5H","outputId":"3524eb76-aa48-4084-8230-baafdfe70b28"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002012 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Ensemble Model Performance:\n","Training RMSE: 7819.6576, MAE: 3127.9306, RÂ²: 0.7784\n","Validation RMSE: 13468.9323, MAE: 3552.7555, RÂ²: 0.3953\n","Holdout RMSE: 11252.5350, MAE: 3433.1455, RÂ²: 0.6422\n"]}],"source":["# Define the new boosting models\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(random_state=42,\n","     n_estimators=500,\n","    learning_rate=0.05,\n","    max_depth=6))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(verbose=0, random_state=42,\n","     n_estimators=500,\n","    learning_rate=0.05,\n","    max_depth=6))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(random_state=42,\n","     n_estimators=500,\n","    learning_rate=0.05))\n","])\n","\n","# Updated Ensemble Model with additional boosting models\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('random_forest', random_forest_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline)\n","    ],\n","    weights=[1, 1, 1, 1, 1]  # Equal weight for all models\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the Ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","print(\"Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43734,"status":"ok","timestamp":1733112701569,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"jyiECuosU65i","outputId":"66fb3c4e-35f7-4e5e-8cee-31a1d614d573"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002410 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Updated Ensemble Model Performance:\n","Training RMSE: 10478.3422, MAE: 3369.8659, RÂ²: 0.6022\n","Validation RMSE: 12901.2331, MAE: 3619.2754, RÂ²: 0.4452\n","Holdout RMSE: 12749.2995, MAE: 3586.3509, RÂ²: 0.5406\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=400,       # Reduced to prevent overfitting\n","        learning_rate=0.03,    # Lower learning rate for better generalization\n","        max_depth=6,\n","        reg_alpha=1.5,         # Increased L1 regularization\n","        reg_lambda=1.5,        # Increased L2 regularization\n","        subsample=0.8,         # Subsampling to prevent overfitting\n","        colsample_bytree=0.8,\n","        min_child_weight=10    # Prevents overfitting small splits\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=400,\n","        learning_rate=0.03,\n","        max_depth=6,\n","        reg_alpha=1.5,\n","        reg_lambda=1.5,\n","        num_leaves=25,        # Fewer leaves to improve generalization\n","        subsample=0.8,\n","        colsample_bytree=0.8\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=400,\n","        learning_rate=0.03,\n","        depth=6,\n","        l2_leaf_reg=3.0,     # Increased regularization\n","        subsample=0.8,\n","        early_stopping_rounds=50  # Early stopping to prevent overfitting\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,    # Reduced number of estimators\n","        learning_rate=0.03   # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=300,    # Balanced tree count\n","        max_depth=8,         # Reduced depth for generalization\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.2, 1.2, 1.0, 0.8, 1.0]  # Emphasize XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":114,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38027,"status":"ok","timestamp":1733112739583,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"05bbrB1qXjov","outputId":"2099aac7-40c7-462b-a253-deca3d1bc67d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001724 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Updated Ensemble Model Performance:\n","Training RMSE: 11974.8823, MAE: 3572.9256, RÂ²: 0.4804\n","Validation RMSE: 13512.8749, MAE: 3781.1948, RÂ²: 0.3913\n","Holdout RMSE: 14062.7866, MAE: 3773.8472, RÂ²: 0.4411\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=350,       # Reduced to prevent overfitting\n","        learning_rate=0.02,    # Lower learning rate for better generalization\n","        max_depth=5,\n","        reg_alpha=2.0,         # Increased L1 regularization\n","        reg_lambda=2.0,        # Increased L2 regularization\n","        subsample=0.85,        # Slightly increased subsampling\n","        colsample_bytree=0.8,\n","        min_child_weight=8     # Balanced child weight to reduce overfitting\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=350,\n","        learning_rate=0.02,\n","        max_depth=5,\n","        reg_alpha=2.0,\n","        reg_lambda=2.0,\n","        num_leaves=20,        # Fewer leaves for better generalization\n","        subsample=0.85,\n","        colsample_bytree=0.8\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=350,\n","        learning_rate=0.02,\n","        depth=5,\n","        l2_leaf_reg=4.0,     # Increased regularization\n","        subsample=0.85,\n","        early_stopping_rounds=50  # Early stopping to prevent overfitting\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,    # Reduced number of estimators\n","        learning_rate=0.02   # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=250,    # Balanced tree count\n","        max_depth=7,         # Reduced depth for generalization\n","        min_samples_split=12,\n","        min_samples_leaf=6,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.3, 1.3, 1.0, 0.7, 1.0]  # Emphasize XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46938,"status":"ok","timestamp":1733112786509,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"7Kt4xL38Zb7r","outputId":"b3a19a84-8585-4a52-8c52-a70a9771c61d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002315 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Updated Ensemble Model Performance:\n","Training RMSE: 9847.6171, MAE: 3192.9381, RÂ²: 0.6486\n","Validation RMSE: 12705.4757, MAE: 3472.8355, RÂ²: 0.4619\n","Holdout RMSE: 12253.9294, MAE: 3416.7250, RÂ²: 0.5756\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=400,       # Slightly increased for better generalization\n","        learning_rate=0.03,    # Lower learning rate for smoother convergence\n","        max_depth=6,            # Increased to capture more interactions\n","        reg_alpha=1.5,          # Balanced regularization\n","        reg_lambda=1.5,         # Balanced regularization\n","        subsample=0.85,         # Avoid overfitting\n","        colsample_bytree=0.9,\n","        min_child_weight=6      # Adjusted for moderate regularization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=400,\n","        learning_rate=0.03,\n","        max_depth=7,            # Slightly deeper trees\n","        reg_alpha=1.5,\n","        reg_lambda=1.5,\n","        num_leaves=30,          # Increased leaves for richer patterns\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=400,\n","        learning_rate=0.03,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=3.5,       # Reduced regularization for improved fit\n","        subsample=0.85,\n","        early_stopping_rounds=50  # Early stopping for better generalization\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=350,       # Increased estimators for better fitting\n","        learning_rate=0.03      # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=300,       # Balanced tree count\n","        max_depth=8,            # Increased depth for richer splits\n","        min_samples_split=10,\n","        min_samples_leaf=4,     # Reduced leaf size to capture more detail\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.5, 1.5, 1.0, 0.8, 1.0]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":116,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41026,"status":"ok","timestamp":1733112827524,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"u2jn2PTgaQna","outputId":"7a52b19a-5b5a-4eb0-9abd-7960ae1fc454"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final Updated Ensemble Model Performance:\n","Training RMSE: 10231.5396, MAE: 3202.6527, RÂ²: 0.6207\n","Validation RMSE: 12620.7782, MAE: 3451.5310, RÂ²: 0.4690\n","Holdout RMSE: 12437.9855, MAE: 3403.3793, RÂ²: 0.5628\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=350,       # Adjusted for smoother convergence\n","        learning_rate=0.025,    # Lower learning rate\n","        max_depth=6,            # Balanced depth for validation\n","        reg_alpha=1.8,          # Adjusted L1 regularization\n","        reg_lambda=2.2,         # Adjusted L2 regularization\n","        subsample=0.85,         # Controlled subsampling\n","        colsample_bytree=0.9,\n","        min_child_weight=7      # Adjusted for generalization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=350,\n","        learning_rate=0.025,\n","        max_depth=7,            # Slightly deeper trees for richer splits\n","        reg_alpha=1.8,\n","        reg_lambda=2.2,\n","        num_leaves=25,          # Balanced leaf count\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=350,\n","        learning_rate=0.025,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=4.0,       # Regularization for generalization\n","        subsample=0.85,\n","        early_stopping_rounds=50\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,      # Balanced estimator count\n","        learning_rate=0.025    # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=250,\n","        max_depth=8,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.6, 1.6, 1.0, 0.7, 1.0]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Final Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40975,"status":"ok","timestamp":1733112868497,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"YWeyc_Okaw6r","outputId":"021aed2c-8448-4325-a14f-11c56bad367c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001693 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final Updated Ensemble Model Performance:\n","Training RMSE: 9926.2790, MAE: 3174.8362, RÂ²: 0.6430\n","Validation RMSE: 12553.8697, MAE: 3431.1843, RÂ²: 0.4746\n","Holdout RMSE: 12174.5629, MAE: 3374.0516, RÂ²: 0.5811\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=350,       # Adjusted for smoother convergence\n","        learning_rate=0.025,    # Lower learning rate\n","        max_depth=6,            # Balanced depth for validation\n","        reg_alpha=1.8,          # Adjusted L1 regularization\n","        reg_lambda=2.2,         # Adjusted L2 regularization\n","        subsample=0.85,         # Controlled subsampling\n","        colsample_bytree=0.9,\n","        min_child_weight=7      # Adjusted for generalization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=350,\n","        learning_rate=0.025,\n","        max_depth=7,            # Slightly deeper trees for richer splits\n","        reg_alpha=1.8,\n","        reg_lambda=2.2,\n","        num_leaves=25,          # Balanced leaf count\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=350,\n","        learning_rate=0.025,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=4.0,       # Regularization for generalization\n","        subsample=0.85,\n","        early_stopping_rounds=50\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,      # Balanced estimator count\n","        learning_rate=0.025    # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=250,\n","        max_depth=8,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.6, 1.6, 1.0, 0.7, 0.5]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Final Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41078,"status":"ok","timestamp":1733112909561,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"326ll_aybFaf","outputId":"bbe14705-814b-4db3-8295-ad36e37ecfe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final Updated Ensemble Model Performance:\n","Training RMSE: 9745.4207, MAE: 2968.7537, RÂ²: 0.6559\n","Validation RMSE: 12279.3420, MAE: 3231.5905, RÂ²: 0.4974\n","Holdout RMSE: 11894.8747, MAE: 3166.0593, RÂ²: 0.6001\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=350,       # Adjusted for smoother convergence\n","        learning_rate=0.025,    # Lower learning rate\n","        max_depth=6,            # Balanced depth for validation\n","        reg_alpha=1.8,          # Adjusted L1 regularization\n","        reg_lambda=2.2,         # Adjusted L2 regularization\n","        subsample=0.85,         # Controlled subsampling\n","        colsample_bytree=0.9,\n","        min_child_weight=7      # Adjusted for generalization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=350,\n","        learning_rate=0.025,\n","        max_depth=7,            # Slightly deeper trees for richer splits\n","        reg_alpha=1.8,\n","        reg_lambda=2.2,\n","        num_leaves=25,          # Balanced leaf count\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=350,\n","        learning_rate=0.025,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=4.0,       # Regularization for generalization\n","        subsample=0.85,\n","        early_stopping_rounds=50\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,      # Balanced estimator count\n","        learning_rate=0.025    # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=250,\n","        max_depth=8,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.6, 1.6, 0.5, 0.4, 0.5]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Final Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41697,"status":"ok","timestamp":1733113113875,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"Ma5h-7mybgOb","outputId":"beafefba-9abc-4f71-bf6c-2629e2b6ca46"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001842 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final Updated Ensemble Model Performance:\n","Training RMSE: 9160.9071, MAE: 2638.3682, RÂ²: 0.6959\n","Validation RMSE: 11918.8231, MAE: 2922.3145, RÂ²: 0.5264\n","Holdout RMSE: 11254.9076, MAE: 2831.1773, RÂ²: 0.6420\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=4242,\n","        n_estimators=350,       # Adjusted for smoother convergence\n","        learning_rate=0.025,    # Lower learning rate\n","        max_depth=6,            # Balanced depth for validation\n","        reg_alpha=1.8,          # Adjusted L1 regularization\n","        reg_lambda=2.2,         # Adjusted L2 regularization\n","        subsample=0.85,         # Controlled subsampling\n","        colsample_bytree=0.9,\n","        min_child_weight=7      # Adjusted for generalization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=4242,\n","        n_estimators=350,\n","        learning_rate=0.025,\n","        max_depth=7,            # Slightly deeper trees for richer splits\n","        reg_alpha=1.8,\n","        reg_lambda=2.2,\n","        num_leaves=25,          # Balanced leaf count\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=4242,\n","        iterations=350,\n","        learning_rate=0.025,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=4.0,       # Regularization for generalization\n","        subsample=0.85,\n","        early_stopping_rounds=50\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=4242,\n","        n_estimators=300,      # Balanced estimator count\n","        learning_rate=0.025    # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=4242,\n","        n_estimators=250,\n","        max_depth=8,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[1.6, 1.6, 0.1, 0.1, 0.1]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Final Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41208,"status":"ok","timestamp":1733112991738,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"wFi7CVqYc0oS","outputId":"b61f7330-6f74-4acf-dc3a-a4d5a40d670b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 949\n","[LightGBM] [Info] Number of data points in the train set: 39523, number of used features: 63\n","[LightGBM] [Info] Start training from score 3927.968702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Final Updated Ensemble Model Performance:\n","Training RMSE: 9684.3373, MAE: 2905.4626, RÂ²: 0.6602\n","Validation RMSE: 12238.6046, MAE: 3170.6019, RÂ²: 0.5007\n","Holdout RMSE: 11830.6605, MAE: 3099.1856, RÂ²: 0.6045\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Updated boosting models\n","xgboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('xgboost', XGBRegressor(\n","        objective='reg:squarederror',\n","        random_state=42,\n","        n_estimators=350,       # Adjusted for smoother convergence\n","        learning_rate=0.025,    # Lower learning rate\n","        max_depth=6,            # Balanced depth for validation\n","        reg_alpha=1.8,          # Adjusted L1 regularization\n","        reg_lambda=2.2,         # Adjusted L2 regularization\n","        subsample=0.85,         # Controlled subsampling\n","        colsample_bytree=0.9,\n","        min_child_weight=7      # Adjusted for generalization\n","    ))\n","])\n","\n","lightgbm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('lightgbm', LGBMRegressor(\n","        objective='regression',\n","        random_state=42,\n","        n_estimators=350,\n","        learning_rate=0.025,\n","        max_depth=7,            # Slightly deeper trees for richer splits\n","        reg_alpha=1.8,\n","        reg_lambda=2.2,\n","        num_leaves=25,          # Balanced leaf count\n","        subsample=0.85,\n","        colsample_bytree=0.9\n","    ))\n","])\n","\n","catboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('catboost', CatBoostRegressor(\n","        verbose=0,\n","        random_state=42,\n","        iterations=350,\n","        learning_rate=0.025,\n","        depth=6,               # Balanced depth\n","        l2_leaf_reg=4.0,       # Regularization for generalization\n","        subsample=0.85,\n","        early_stopping_rounds=50\n","    ))\n","])\n","\n","adaboost_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('adaboost', AdaBoostRegressor(\n","        random_state=42,\n","        n_estimators=300,      # Balanced estimator count\n","        learning_rate=0.025    # Lower learning rate for smoother fit\n","    ))\n","])\n","\n","random_forest_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('random_forest', RandomForestRegressor(\n","        random_state=42,\n","        n_estimators=250,\n","        max_depth=8,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        max_features='sqrt'\n","    ))\n","])\n","\n","# Updated ensemble model\n","ensemble_model = VotingRegressor(\n","    estimators=[\n","        ('xgboost', xgboost_pipeline),\n","        ('lightgbm', lightgbm_pipeline),\n","        ('catboost', catboost_pipeline),\n","        ('adaboost', adaboost_pipeline),\n","        ('random_forest', random_forest_pipeline)\n","    ],\n","    weights=[2.0, 1.9, 0.7, 0.4, 0.6]  # Increased emphasis on XGBoost and LightGBM\n",")\n","\n","# Train the ensemble model\n","ensemble_model.fit(X_train, y_train)\n","\n","# Evaluate the ensemble model\n","y_train_pred_ensemble = ensemble_model.predict(X_train)\n","y_val_pred_ensemble = ensemble_model.predict(X_val)\n","y_holdout_pred_ensemble = ensemble_model.predict(X_holdout)\n","\n","train_rmse_ensemble = mean_squared_error(y_train, y_train_pred_ensemble, squared=False)\n","val_rmse_ensemble = mean_squared_error(y_val, y_val_pred_ensemble, squared=False)\n","holdout_rmse_ensemble = mean_squared_error(y_holdout, y_holdout_pred_ensemble, squared=False)\n","\n","train_mae_ensemble = mean_absolute_error(y_train, y_train_pred_ensemble)\n","val_mae_ensemble = mean_absolute_error(y_val, y_val_pred_ensemble)\n","holdout_mae_ensemble = mean_absolute_error(y_holdout, y_holdout_pred_ensemble)\n","\n","train_r2_ensemble = ensemble_model.score(X_train, y_train)\n","val_r2_ensemble = ensemble_model.score(X_val, y_val)\n","holdout_r2_ensemble = ensemble_model.score(X_holdout, y_holdout)\n","\n","# Print results\n","print(\"Final Updated Ensemble Model Performance:\")\n","print(f\"Training RMSE: {train_rmse_ensemble:.4f}, MAE: {train_mae_ensemble:.4f}, RÂ²: {train_r2_ensemble:.4f}\")\n","print(f\"Validation RMSE: {val_rmse_ensemble:.4f}, MAE: {val_mae_ensemble:.4f}, RÂ²: {val_r2_ensemble:.4f}\")\n","print(f\"Holdout RMSE: {holdout_rmse_ensemble:.4f}, MAE: {holdout_mae_ensemble:.4f}, RÂ²: {holdout_r2_ensemble:.4f}\")"]},{"cell_type":"markdown","source":["# Predictions"],"metadata":{"id":"EkBS-n27mhYk"}},{"cell_type":"code","source":["# Redefine dummy data for fitting\n","X_excluded = pred[[ 'Vodka', 'Store_Size_Extra Large',\n","          'Store_Size_Large', 'Store_Size_Medium', 'Store_Size_Small', 'Store_State_AZ', 'Store_State_CA',\n","          'Store_State_CO', 'Store_State_CT', 'Store_State_DE', 'Store_State_FL', 'Store_State_GA',\n","          'Store_State_IL', 'Store_State_IN', 'Store_State_KS', 'Store_State_KY', 'Store_State_LA',\n","          'Store_State_MA', 'Store_State_MD', 'Store_State_MI', 'Store_State_MN', 'Store_State_MO',\n","          'Store_State_NJ', 'Store_State_NM', 'Store_State_NV', 'Store_State_NY', 'Store_State_SC',\n","          'Store_State_TN', 'Store_State_TX', 'Store_State_WA', 'Store_State_WI', 'Package_Type_1.5L',\n","          'Package_Type_1.75L', 'Package_Type_1.75Lgft', 'Package_Type_100ml', 'Package_Type_1L',\n","          'Package_Type_200-3gft', 'Package_Type_200ml', 'Package_Type_375ml', 'Package_Type_700ml',\n","          'Package_Type_720ml', 'Package_Type_750gft', 'Package_Type_750ml', 'Count_Week_Instock_Normalized',\n","          'log_Retail_Price', 'log_Households', 'log_Store_Age_Days', 'Cluster_Label',\n","          'Vodka_Tequila_Under_65_Ratio', 'Vodka_Tequila_Over_65_Ratio', 'Vodka_Wine_Ratio',\n","          'Spirits_Direct', 'Flavored_Vodka', 'Top20_Vodka']]\n","\n","# Predict with ensemble model\n","y_excluded_pred = ensemble_model.predict(X_excluded)\n","\n","# Add predictions to the DataFrame\n","pred['Predicted_Sales'] = y_excluded_pred\n","\n","# Save predictions to CSV\n","output_path = \"df_excluded_predictions.csv\"\n","pred[['Store_Number', 'Item_Code', 'Predicted_Sales']].to_csv(output_path, index=False)\n","output_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"Q4Cswc_CmCZy","executionInfo":{"status":"ok","timestamp":1733113248774,"user_tz":300,"elapsed":653,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"}},"outputId":"cd6a57df-03ce-499f-a9c6-e814b46765a8"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-123-84898cf030df>:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pred['Predicted_Sales'] = y_excluded_pred\n"]},{"output_type":"execute_result","data":{"text/plain":["'df_excluded_predictions.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"OF9FaTbrPyPG"},"source":["# ML"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4595,"status":"ok","timestamp":1732568928932,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"UwBWE8IHPxXd","outputId":"e8aa8325-3d88-4ee3-820b-6da6abf36b06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj_8JbvvP3ko"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":183474,"status":"ok","timestamp":1732569118077,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"K-Mqv0c3P7qQ","outputId":"bdb9c9ce-3edf-4444-db86-82377f088288"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1236/1236\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n","\u001b[1m309/309\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","\u001b[1m172/172\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"]}],"source":["# Define features and target\n","data = df_cleaned[df_cleaned['Sales Bucket'] == 'Sales included']\n","X = data[['Vodka', 'Store_Size_Extra Large',\n","          'Store_Size_Large', 'Store_Size_Medium', 'Store_Size_Small', 'Store_State_AZ', 'Store_State_CA',\n","          'Store_State_CO', 'Store_State_CT', 'Store_State_DE', 'Store_State_FL', 'Store_State_GA',\n","          'Store_State_IL', 'Store_State_IN', 'Store_State_KS', 'Store_State_KY', 'Store_State_LA',\n","          'Store_State_MA', 'Store_State_MD', 'Store_State_MI', 'Store_State_MN', 'Store_State_MO',\n","          'Store_State_NJ', 'Store_State_NM', 'Store_State_NV', 'Store_State_NY', 'Store_State_SC',\n","          'Store_State_TN', 'Store_State_TX', 'Store_State_WA', 'Store_State_WI', 'Package_Type_1.5L',\n","          'Package_Type_1.75L', 'Package_Type_1.75Lgft', 'Package_Type_100ml', 'Package_Type_1L',\n","          'Package_Type_200-3gft', 'Package_Type_200ml', 'Package_Type_375ml', 'Package_Type_700ml',\n","          'Package_Type_720ml', 'Package_Type_750gft', 'Package_Type_750ml', 'Count_Week_Instock_Normalized',\n","          'log_Retail_Price', 'log_Households', 'log_Store_Age_Days', 'Cluster_Label',\n","          'Vodka_Tequila_Under_65_Ratio', 'Vodka_Tequila_Over_65_Ratio', 'Vodka_Wine_Ratio',\n","          'Spirits_Direct', 'Flavored_Vodka', 'Top20_Vodka']]\n","y = data['Normalized_Sales_$L52W']\n","\n","# Split into train, validation, and holdout sets\n","X_train_val, X_holdout, y_train_val, y_holdout = train_test_split(X, y, test_size=0.1, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n","\n","# Preprocessing pipeline\n","numerical_features = ['Vodka', 'Count_Week_Instock_Normalized', 'log_Retail_Price',\n","                      'log_Households', 'log_Store_Age_Days', 'Vodka_Tequila_Under_65_Ratio',\n","                      'Vodka_Tequila_Over_65_Ratio', 'Vodka_Wine_Ratio']\n","categorical_features = ['Store_Size_Extra Large', 'Store_Size_Large', 'Store_Size_Medium',\n","                        'Store_Size_Small', 'Store_State_AZ', 'Store_State_CA', 'Store_State_CO',\n","                        'Store_State_CT', 'Store_State_DE', 'Store_State_FL', 'Store_State_GA',\n","                        'Store_State_IL', 'Store_State_IN', 'Store_State_KS', 'Store_State_KY',\n","                        'Store_State_LA', 'Store_State_MA', 'Store_State_MD', 'Store_State_MI',\n","                        'Store_State_MN', 'Store_State_MO', 'Store_State_NJ', 'Store_State_NM',\n","                        'Store_State_NV', 'Store_State_NY', 'Store_State_SC', 'Store_State_TN',\n","                        'Store_State_TX', 'Store_State_WA', 'Store_State_WI', 'Package_Type_1.5L',\n","                        'Package_Type_1.75L', 'Package_Type_1.75Lgft', 'Package_Type_100ml',\n","                        'Package_Type_1L', 'Package_Type_200-3gft', 'Package_Type_200ml',\n","                        'Package_Type_375ml', 'Package_Type_700ml', 'Package_Type_720ml',\n","                        'Package_Type_750gft', 'Package_Type_750ml', 'Cluster_Label',\n","                        'Spirits_Direct', 'Flavored_Vodka', 'Top20_Vodka']\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numerical_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n","    ])\n","\n","# Preprocess data\n","X_train_preprocessed = preprocessor.fit_transform(X_train)\n","X_val_preprocessed = preprocessor.transform(X_val)\n","X_holdout_preprocessed = preprocessor.transform(X_holdout)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    Dense(64, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    Dense(32, activation='relu'),\n","    Dense(1)  # Single output for regression\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# Train the model\n","history = model.fit(\n","    X_train_preprocessed, y_train,\n","    epochs=60,  # Increased epochs for better convergence\n","    batch_size=40,\n","    validation_data=(X_val_preprocessed, y_val),\n","    verbose=0\n",")\n","\n","# Evaluate the model\n","y_train_pred_nn = model.predict(X_train_preprocessed).flatten()\n","y_val_pred_nn = model.predict(X_val_preprocessed).flatten()\n","y_holdout_pred_nn = model.predict(X_holdout_preprocessed).flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1732569118077,"user":{"displayName":"Pravah Pravin Malunjkar","userId":"03763761075930665897"},"user_tz":300},"id":"TFGu0AucWx3E","outputId":"5b419ef8-530c-4010-b78d-798d3d7bcde2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Neural Network Model Performance:\n","Training RMSE: 14600.0732\n","Training MAE: 3019.0694\n","Validation RMSE: 22907.4637\n","Validation MAE: 3493.4610\n","Holdout RMSE: 15644.8552\n","Holdout MAE: 3141.3507\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]}],"source":["# Metrics\n","def evaluate_model_nn(y_true, y_pred, set_name):\n","    rmse = mean_squared_error(y_true, y_pred, squared=False)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    print(f\"{set_name} RMSE: {rmse:.4f}\")\n","    print(f\"{set_name} MAE: {mae:.4f}\")\n","\n","print(\"Neural Network Model Performance:\")\n","evaluate_model_nn(y_train, y_train_pred_nn, \"Training\")\n","evaluate_model_nn(y_val, y_val_pred_nn, \"Validation\")\n","evaluate_model_nn(y_holdout, y_holdout_pred_nn, \"Holdout\")"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}